---
title: "Final Report: Regression Problem"
subtitle: |
  | Regression Problem 
  | Data Science 3 with R (STAT 301-3)
author: "Reed Malcolm"
pagetitle: "Regression Probelm Reed Malcolm"
date: today
format:
  html:
    
    toc: true
    embed-resources: true
execute:
  warning: false
from: markdown+emoji 
reference-location: margin
citation-location: margin
editor: 
  markdown: 
    wrap: 72
---

```{r}
#| label: load-data-and-packages
#| echo: false

# loading packages
library(tidyverse)
library(here)

# loading objects

```


::: {.callout-tip icon="false"}
## Github Repo Link

[Reed's Regression Problem GitHub
Repo](https://github.com/stat301-3-2025-spring/reg-pred-prob-malcor21.git)
:::

## Introduction

Price prediction using machine learning has become increasingly prominent in the rental 
space due to the prevalence of rate-recommendation platforms like RealPage.[^1] 
Machine learning is particularly amenable to rental properties on the basis of 
their wealth of physical and administrative qualities to guide prediction. A 
timeshare service like Airbnb could utilize such methods, for example, to advise 
hosts’ pricing decisions based on listing characteristics. 

This regression exercise seeks to construct that type of model, using machine learning workflows to predict Airbnb rental prices based on physical and demographic qualities. As part of a coursewide data science competition, this prediction problem adheres to the model building and submission guidelines listed on the corresponding Kaggle page. Airbnb listing data for the exercise was also provided on Kaggle.[^2] 

The Airbnb regression prediction problem seeks to forecast price using modeling
techniques covered in the Stat 301 course sequence. This repository is structured
by workflow, with each pipeline constituting a wave of model submissions to the Kaggle
competition. Workflows consist of all predictive modeling steps save for data cleaning: variable
selection, preprocessing, model fitting and tuning, evaluation, and final fitting.
A variety of model types were employed for the exercise, including generalized linear, random
forest, boosted trees, k-nearest neighbors, and neural network workflows. Submission
pipelines were constructed until the A grade threshold, a mean absolute error (MAE) of
97 or less, was achieved by a generated model. This report examines two models
from the project: a boosted trees workflow that exceeded the A threshold, and a random
forest model to discuss robustness.

[^1]: Vegari, A. and Anderson, C (2025), [RealPage Opens New Front in Algorithmic Pricing Challenges with Suit Challenging Berkeley Ordinance](https://www.pbwt.com/antitrust-update-blog/realpage-opens-new-front-in-algorithmic-pricing-challenges-with-suit-challenging-berkeley-ordinance)

[^2]: Arend Kuyper (2025), [Regression (Spring 2025): Airbnb prices](https://www.kaggle.com/competitions/regression-spring-2025-airbnb-prices/overview)


## Selected Model 1

The first selected model was `rf1_11_predict.csv`, the strongest random forest model generated
during the first submission wave.

![Submission Set 1 Models, Ranked](figures/s1_autoplot.jpg){#fig-s1-autoplot}

The first submission set took a broad approach to predicting price. After implementing
the basic data cleaning steps for information extraction discussed in class---capturing 
common amenities, bathrooms per listing, etc.---I utilized a kitchen-sink philosophy
for tuning and preprocessing. Variable selection was conducted using a minimal-processing
random forest model, retrieving an arbitrary 23 variables for use in prediction.
Preprocessing objects were generated for the five model types mentioned above utilizing only
the required steps, and parameter values were mostly assigned to the default tuning ranges.
The best models of each workflow type were advanced to the public Kaggle leaderboard
for evaluation; the submitted models performed in the same relative order as their training
results.

```{r}
#| label: tbl-s1
#| echo: false
#| tbl-cap: "Submission 1 Optimal Model Results"

tribble(
  ~Model_Type, ~Optimal_Model_Name, ~Public_MAE,
  "Boosted trees", "bt1_096_predict.csv", 104.55,
  "Random forest", "rf1_11_predict.csv", 105.55,
  "K-nearest neighbors", "knn1_6_predict.csv", 117.97,
  "Neural network", "mlp1_2_predict.csv", 137.25,
  "Generalized linear model", "lasso1_1_predict.csv", 149.39
) %>% 
  knitr::kable()
```


As shown in @tbl-s1 above, the optimal boosted trees model proved the strongest of the
first wave submissions. Further boosted trees tuning was therefore pursued in the
later pipelines. However, the best random forest model finished not far behind the
boosted trees. I have selected `rf1_11_predict.csv`, the best-performing non-boosted trees model tested
during the exercise, as a benchmark for private leaderboard evaluation.

While the boosted trees workflow underwent extensive tuning during the subsequent
two submission pipelines, the first wave's optimal random forest model performed respectably 
with little to no bespoke adjustments. I am therefore interested to compare `rf1_11_predict.csv`'s
private leaderboard power to that of the second selected model, which was likely 
overfitted to the public leaderboard on account of its extensive parameter tuning.
Even if the first wave's random forest model does not strictly outperform its boosted
trees counterpart, a low relative MAE could demonstrate that the former is more generalizable
to foreign Airbnb data and thus worth exploring further in the future.

## Selected Model 2

The second selected model, `bt1_07_all_predict.csv`, crossed the A grade threshold
with a MAE of 96.7 on the public leaderboard. It was the best-performing boosted
trees workflow from the third submission wave as well as overall.

In line with the results of the first pass, the second submission wave focused on 
fine-tuning the boosted trees workflow. The second submission abandoned the variable
selection step (as per our discussions in class), increased the number of included
amenity indicators, and added predictors extracting further text information. 
I also transitioned to using the `lightgbm` engine for boosted trees tuning and 
allowed for variation in the workflow's tree depth and minimum loss reduction. Overall,
the second submission's optimal boosted trees model demonstrated a modest improvement to
an MAE of 99.18 on the public Kaggle leaderboard.

![Submission Set 2 Boosted Trees Tuning](figures/s2_bt_autoplot.jpg){#fig-s2-bt-autoplot}

The third submission set built upon the previous wave with some minor tweaks. I added
a few metavariables during preprocessing, such as foreign host ownership and a count
of amenities. A lasso variable selection was also implemented, although it produced
relatively less powerful models than the no-selection path. Most impactfully, I 
narrowed the boosted trees workflow's hyperparameter tuning ranges based on
the second submission wave results, shown above in @fig-s2-bt-autoplot. For the third
wave I increased the number of trees to between 1200 and 2800 and reduced the tree
depth and minimum loss reduction values. 

These changes produced `bt1_07_all_predict.csv`,
which used a no-variable selection recipe to exceed the public Kaggle leaderboard's 
A threshold; no further modeling was attempted. Still, overfitting remained a 
concern as with any boosted trees workflow, and simply increasing the number of trees
to improve predictive power did not seem like the most computationally efficient
practice.

## Conclusion

After our class discussions as well as evaluating the classification problem results,
I anticipated a boosted trees workflow to perform best on this regression exercise. 
My expectation seemed to hold, with only light preprocessing and hyperparameter
tuning (as well as fewer submission pipelines compared to the classification problem)
being required to achieve the A threshold using a `lightgbm` boosted trees model. 
Overall, boosted trees proved a powerful ML pathway for predicting listing price---even
if the A threshold was a rather large mean absolute error of $97---that could
be utilized by firms or individuals in the rental market.

As we have mentioned during past projects, the second selected model is likely overfit
to the public leaderboard data due to both its gains being tuning-dependent and the
general nature of boosted trees modeling. It is also worrying that simply increasing
the number of trees seemed to drive growth in predictive power: for practical purposes
a useful machine learnig
workflow should be not just accurate but also efficient, even if reducing computation
time was not a focus of this exercise. 

I chose a random forest model generated with default
tuning range, `rf1_11_predict.csv`, as my second selected model to acknowledge the 
issue of boosted trees overfitting. As a tree-based workflow, though, the random forest model
might still suffer from overfitting. However, none of the other tested workflows---a generalized
linear model, k-nearest neighbors, a multilayer neural network---demonstrated comparable
performances on their own. Constructing an ensemble model could therefore be an attractive
future direction, combining a broad tree-based instance with the other workflows for
a more generalizable tool. In future price prediction problems, I would be interested in
dedicating more attention to tuning and incorporating non-tree workflows for a more
holistic approach.

## AI Statement

Generative AI resources (Chat GPT-4o and perplexity.ai) to generate helper code 
during the project’s data cleaning process. Specifically, I used Generative AI to produce
complex regular expressions and generate functions for cleaning amenities data. 
